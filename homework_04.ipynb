{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27cc1be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import random\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2050cfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_data, y_labels = datasets.make_classification(n_features=2, n_informative=2, \n",
    "                                                n_classes=2, n_redundant=0, \n",
    "                                                n_clusters_per_class=1, \n",
    "                                                random_state=5)\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(X_data, \n",
    "                                                                    y_labels, \n",
    "                                                                    test_size = 0.3,\n",
    "                                                                    random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7252dabb",
   "metadata": {},
   "source": [
    "#### 1. В коде из методички реализуйте один или несколько критериев останова: \n",
    "- минимальное количество объектов в листе (`min_leaf`), \n",
    "- максимальная глубина дерева, \n",
    "- максимальное количество листьев и т.д. \n",
    "\n",
    "Добавьте эти критерии в параметры функции `build_tree` и проверьте ее работоспособность с помощью визуализации дерева (функция `print_tree()`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67780c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree_stop_criteria(data, labels, min_samples_leaf=1, max_depth=6, max_leaf_nodes=None):\n",
    "    \n",
    "    \"\"\"Итоговая модифицированная функция построения дерева выглядит так.\n",
    "       Я проверял её на модели из урока. Работает корректно.\n",
    "       Я не стал заморачиваться с критерием 'максимального количества листьев в дереве'.\n",
    "       Чтобы довести работу функции с этим критерием до ума потребовалось бы много времени + неинтересно. \n",
    "       Я лучше потрачу время на остальные задания)))\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    min_leaf = min_samples_leaf\n",
    "    quality, t, index = find_best_split(data, labels, min_samples_leaf=min_leaf)\n",
    "\n",
    "    if (t is None) or (index is None):\n",
    "        return Leaf(data, labels)\n",
    "\n",
    "    true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "\n",
    "    if (len(true_data) <= min_samples_leaf) or (len(false_data) <= min_samples_leaf):\n",
    "        return Leaf(data, labels)\n",
    "\n",
    "    if max_depth is not None:\n",
    "        if max_depth != 0:\n",
    "            max_d = max_depth - 1\n",
    "            true_branch = build_tree_stop_criteria(true_data, true_labels, \n",
    "                                               min_samples_leaf=min_leaf, max_depth=max_d)\n",
    "            false_branch = build_tree_stop_criteria(false_data, false_labels, \n",
    "                                                min_samples_leaf=min_leaf, max_depth=max_d)\n",
    "        else:\n",
    "            return Leaf(data, labels)\n",
    "    else:\n",
    "        true_branch = build_tree_stop_criteria(true_data, true_labels, min_samples_leaf=min_leaf)\n",
    "        false_branch = build_tree_stop_criteria(false_data, false_labels, min_samples_leaf=min_leaf)\n",
    "\n",
    "    return Node(index, t, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77789d7a",
   "metadata": {},
   "source": [
    "Я попробовал применить в качестве критерия останова максимальное количество листьев в дереве `max_leaf_nodes`, но решение мне показалось довольно громоздким: нужно или заранее (до построения дерева) знать сколько листьев будет чтобы что-то предпринять или же нужно будет после построения дерева посчитать сколько листьев получилось и образать лишние, у которых метрики самые плохие - это тоже нужно заморочиться.\n",
    "\n",
    "Однако есть одна мысль. Поскольку каждая ветка и каждый узел заканчивается листом и учитывая, что наше дерево строиться бинарным делением - количество листов зависим от количество нодов и, следоватеьно, от количества уровней. Максимальное количество листьев при $n$ уровнях равно $2^n$, но может быть и меньше, т.к. некоторые ветки могут обрываться не доходя до самого нижнего уровня.\n",
    "\n",
    "Следовательно можно попытаться учитывать количество листьев при построении нового уровня. Позже к этому вернусь.\n",
    "\n",
    "---\n",
    "не буду использовать этот критерий."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008d881e",
   "metadata": {},
   "source": [
    "##### Ниже - Модель (все функции в одной ячейке) взятая из урока для проверки корректности работы новой функции: `build_tree_stop_criteria`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "563748c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index\n",
    "        self.t = t\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "        \n",
    "\n",
    "class Leaf:\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.prediction = self.predict()\n",
    "    def predict(self):\n",
    "        classes = {}\n",
    "        for label in self.labels:\n",
    "            if label not in classes:\n",
    "                classes[label] = 0 \n",
    "            classes[label] += 1\n",
    "        prediction = max(classes, key=classes.get)\n",
    "        return prediction\n",
    "\n",
    "    \n",
    "def gini(labels):\n",
    "    classes = {}\n",
    "    for label in labels:\n",
    "        if label not in classes:\n",
    "            classes[label] = 0\n",
    "        classes[label] += 1\n",
    "    impurity = 1\n",
    "    for label in classes:\n",
    "        p = classes[label] / len(labels)\n",
    "        impurity -= p ** 2\n",
    "    return impurity\n",
    "\n",
    "\n",
    "def quality(left_labels, right_labels, current_gini):\n",
    "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "    return current_gini - p * gini(left_labels) - (1 - p) * gini(right_labels)\n",
    "\n",
    "\n",
    "def split(data, labels, index, t):\n",
    "    left = np.where(data[:, index] <= t)\n",
    "    right = np.where(data[:, index] > t)\n",
    "    true_data = data[left]\n",
    "    false_data = data[right]\n",
    "    true_labels = labels[left]\n",
    "    false_labels = labels[right]\n",
    "    return true_data, false_data, true_labels, false_labels\n",
    "\n",
    "\n",
    "def find_best_split(data, labels, min_samples_leaf=5):\n",
    "    min_leaf = min_samples_leaf\n",
    "    current_gini = gini(labels)\n",
    "    best_quality = 0\n",
    "    best_t = None\n",
    "    best_index = None\n",
    "    n_features = data.shape[1]\n",
    "    for index in range(n_features):\n",
    "        t_values = np.unique([row[index] for row in data])\n",
    "        for t in t_values:\n",
    "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "            if len(true_data) < min_leaf or len(false_data) < min_leaf:\n",
    "                continue\n",
    "            current_quality = quality(true_labels, false_labels, current_gini)\n",
    "            if current_quality > best_quality:\n",
    "                best_quality, best_t, best_index = current_quality, t, index\n",
    "    return best_quality, best_t, best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1d8a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorText:\n",
    "    PURPLE = '\\033[1;35;48m'\n",
    "    CYAN = '\\033[1;36;48m'\n",
    "    BOLD = '\\033[1;39;48m'\n",
    "    GREEN = '\\033[1;34;48m'\n",
    "    BLUE = '\\033[1;44;48m'\n",
    "    ORANGE = '\\033[1;32;48m'\n",
    "    YELLOW = '\\033[1;33;48m'\n",
    "    RED = '\\033[1;31;48m'\n",
    "    BLACK = '\\033[1;30;48m'\n",
    "    UNDERLINE = '\\033[1;37;48m'\n",
    "    END = '\\033[1;37;0m'\n",
    "\n",
    "def print_tree(node, spacing=\"\"):\n",
    "    if isinstance(node, Leaf):\n",
    "        print(ColorText.ORANGE + spacing + ' ЛИСТ' \n",
    "                  + ': прогноз = ' + str(node.prediction) \n",
    "                  + ', объектов = ' + str(len(node.labels)) \n",
    "                  + ColorText.END)\n",
    "        return\n",
    "    print(ColorText.GREEN + spacing + 'УЗЕЛ'  \n",
    "              + ': индекс = ' + str(node.index) \n",
    "              + ', порог = ' + str(round(node.t, 2))\n",
    "              + ColorText.END)\n",
    "    print (spacing + '--> Левая ветка:')\n",
    "    print_tree(node.true_branch, spacing + \"   \")\n",
    "    print (spacing + '--> Правая ветка:')\n",
    "    print_tree(node.false_branch, spacing + \"   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65644c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34;48mУЗЕЛ: индекс = 0, порог = 0.16\u001b[1;37;0m\n",
      "--> Левая ветка:\n",
      "\u001b[1;34;48m   УЗЕЛ: индекс = 1, порог = -1.52\u001b[1;37;0m\n",
      "   --> Левая ветка:\n",
      "\u001b[1;32;48m       ЛИСТ: прогноз = 0, объектов = 12\u001b[1;37;0m\n",
      "   --> Правая ветка:\n",
      "\u001b[1;32;48m       ЛИСТ: прогноз = 0, объектов = 28\u001b[1;37;0m\n",
      "--> Правая ветка:\n",
      "\u001b[1;32;48m    ЛИСТ: прогноз = 1, объектов = 30\u001b[1;37;0m\n"
     ]
    }
   ],
   "source": [
    "# строим дерево, визуализируем его и проверяем корректность работы.\n",
    "my_tree = build_tree_stop_criteria(train_data, train_labels, \n",
    "                               min_samples_leaf=10, max_depth=6, max_leaf_nodes=None)\n",
    "print_tree(my_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b46e49",
   "metadata": {},
   "source": [
    "Все работает корректно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58080da",
   "metadata": {},
   "source": [
    "### 2. (\\*) Для задачи классификации обучите дерево решений с использованием критериев разбиения Джини и Энтропия. \n",
    "Сравните качество классификации, сделайте выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede48426",
   "metadata": {},
   "source": [
    "#### Ниже (в рамках второго задания) пытаюсь построить ООП-модель на базе функций использованных на уроке."
   ]
  },
  {
   "cell_type": "raw",
   "id": "97572e4e",
   "metadata": {},
   "source": [
    "# смотрел как устроены 'под капотом' классы и методы sklearn-овского дерева, чтобы взять за образец.\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "cls = DecisionTreeClassifier??\n",
    "cls.fit??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077647e6",
   "metadata": {},
   "source": [
    "### Модель в ООП-стиле."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97dfd219",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_DecisionTreeClassifier:\n",
    "    \n",
    "    def __init__(self, criterion=\"gini\", min_samples_leaf=1, max_leaf_nodes=None):\n",
    "        self.criterion = criterion\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        \n",
    "    def fit(self, data, labels, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        quality, t, index = Node.find_best_split(self, data, labels)\n",
    "        if (t is None) or (index is None):\n",
    "            return Leaf(data, labels)\n",
    "        true_data, false_data, true_labels, false_labels = Node.split(data, labels, index, t)\n",
    "        if (len(true_data) <= self.min_samples_leaf) or (len(false_data) <= self.min_samples_leaf):\n",
    "            return Leaf(data, labels)\n",
    "        if max_depth is not None:\n",
    "            if max_depth != 0:\n",
    "                max_d = max_depth - 1\n",
    "                true_branch = my_DecisionTreeClassifier.fit(self, true_data, true_labels, \n",
    "                                                            max_depth=max_d)\n",
    "                false_branch = my_DecisionTreeClassifier.fit(self, false_data, false_labels, \n",
    "                                                             max_depth=max_d)\n",
    "            else:\n",
    "                return Leaf(data, labels)\n",
    "        else:\n",
    "            true_branch = my_DecisionTreeClassifier.fit(self, true_data, true_labels)\n",
    "            false_branch = my_DecisionTreeClassifier.fit(self, false_data, false_labels)\n",
    "        self.dtree = Node(index, t, true_branch, false_branch)\n",
    "        # т.е. метод fit() возвращает атрибут объекта classifier (экземпляра класса \n",
    "        # my_DecisionTreeClassifier) содержащий обученный экземпляр дерева (объекта класса Node),\n",
    "        # т.е. обученное дерево.\n",
    "        return self.dtree\n",
    "    \n",
    "    @staticmethod\n",
    "    def classify_obj(obj, node):\n",
    "        if isinstance(node, Leaf):\n",
    "            answer = node.prediction\n",
    "            return answer\n",
    "        if obj[node.index] <= node.t:\n",
    "            return my_DecisionTreeClassifier.classify_obj(obj, node.true_branch)\n",
    "        else:\n",
    "            return my_DecisionTreeClassifier.classify_obj(obj, node.false_branch)\n",
    "    \n",
    "    def labels_predict(self, X):\n",
    "        pred_vec = []\n",
    "        for obj in X:\n",
    "            pred_val = my_DecisionTreeClassifier.classify_obj(obj, self.dtree)\n",
    "            pred_vec.append(pred_val)\n",
    "        return pred_vec\n",
    "    \n",
    "######    \n",
    "class Leaf:\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.prediction = self.predict()\n",
    "    def predict(self):\n",
    "        classes = {}\n",
    "        for label in self.labels:\n",
    "            if label not in classes:\n",
    "                classes[label] = 0 \n",
    "            classes[label] += 1\n",
    "        prediction = max(classes, key=classes.get)\n",
    "        return prediction\n",
    "    \n",
    "######    \n",
    "class Node:\n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index\n",
    "        self.t = t\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "\n",
    "    @staticmethod\n",
    "    def gini(labels):\n",
    "        classes = {}\n",
    "        for label in labels:\n",
    "            if label not in classes:\n",
    "                classes[label] = 0\n",
    "            classes[label] += 1\n",
    "        impurity = 1\n",
    "        for label in classes:\n",
    "            p = classes[label] / len(labels)\n",
    "            impurity -= p ** 2\n",
    "        return impurity\n",
    "    \n",
    "    @staticmethod\n",
    "    def entropy(labels):\n",
    "        classes = {}\n",
    "        for label in labels:\n",
    "            if label not in classes:\n",
    "                classes[label] = 0\n",
    "            classes[label] += 1\n",
    "        entropy_index = 0\n",
    "        for label in classes:\n",
    "            p = classes[label] / len(labels)\n",
    "            entropy_index -= 0 if p == 0 else p*np.log2(p)\n",
    "        return entropy_index\n",
    "\n",
    "    @staticmethod\n",
    "    def quality(left_labels, right_labels, criterion, current_criteria):\n",
    "        weig = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "        if criterion == 'gini':\n",
    "            return current_criteria - weig * Node.gini(left_labels) \\\n",
    "                                                                - (1 - weig) * Node.gini(right_labels)\n",
    "        elif criterion == 'entropy':\n",
    "            return current_criteria - weig * Node.entropy(left_labels) \\\n",
    "                                                                - (1 - weig) * Node.entropy(right_labels)\n",
    "    \n",
    "    @staticmethod\n",
    "    def split(data, labels, index, t):\n",
    "        left = np.where(data[:, index] <= t)\n",
    "        right = np.where(data[:, index] > t)\n",
    "        true_data = data[left]\n",
    "        false_data = data[right]\n",
    "        true_labels = labels[left]\n",
    "        false_labels = labels[right]\n",
    "        return true_data, false_data, true_labels, false_labels\n",
    "    \n",
    "    def find_best_split(self, data, labels):\n",
    "        if self.criterion == 'gini':\n",
    "            current_criteria = Node.gini(labels)\n",
    "        elif self.criterion == 'entropy':\n",
    "            current_criteria = Node.entropy(labels)\n",
    "        best_quality = 0\n",
    "        best_t = None\n",
    "        best_index = None\n",
    "        n_features = data.shape[1]\n",
    "        for index in range(n_features):\n",
    "            t_values = np.unique([row[index] for row in data])\n",
    "            for t in t_values:\n",
    "                true_data, false_data, true_labels, false_labels = Node.split(data, labels, index, t)\n",
    "                if len(true_data) < self.min_samples_leaf or len(false_data) < self.min_samples_leaf:\n",
    "                    continue\n",
    "                current_quality = Node.quality(true_labels, false_labels, \n",
    "                                               self.criterion, current_criteria)\n",
    "                if current_quality > best_quality:\n",
    "                    best_quality, best_t, best_index = current_quality, t, index\n",
    "        return best_quality, best_t, best_index\n",
    "\n",
    "    @staticmethod\n",
    "    def accuracy_metric(actual, predicted):\n",
    "        correct = 0\n",
    "        for i in range(len(actual)):\n",
    "            if actual[i] == predicted[i]:\n",
    "                correct += 1\n",
    "        return correct / float(len(actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ab3d4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34;48mУЗЕЛ: индекс = 0, порог = 0.16\u001b[1;37;0m\n",
      "--> Левая ветка:\n",
      "\u001b[1;34;48m   УЗЕЛ: индекс = 1, порог = -1.52\u001b[1;37;0m\n",
      "   --> Левая ветка:\n",
      "\u001b[1;34;48m      УЗЕЛ: индекс = 0, порог = -0.95\u001b[1;37;0m\n",
      "      --> Левая ветка:\n",
      "\u001b[1;32;48m          ЛИСТ: прогноз = 0, объектов = 6\u001b[1;37;0m\n",
      "      --> Правая ветка:\n",
      "\u001b[1;32;48m          ЛИСТ: прогноз = 1, объектов = 6\u001b[1;37;0m\n",
      "   --> Правая ветка:\n",
      "\u001b[1;32;48m       ЛИСТ: прогноз = 0, объектов = 28\u001b[1;37;0m\n",
      "--> Правая ветка:\n",
      "\u001b[1;32;48m    ЛИСТ: прогноз = 1, объектов = 30\u001b[1;37;0m\n"
     ]
    }
   ],
   "source": [
    "my_cls = my_DecisionTreeClassifier(criterion='entropy', min_samples_leaf=5)\n",
    "my_cls.fit(train_data, train_labels, max_depth=None)\n",
    "print_tree(my_cls.dtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e41ba6",
   "metadata": {},
   "source": [
    "##### Ну вроде работает также как в функциональном стиле)))\n",
    "\n",
    "Убил на это ну очень много времени ((("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7655309e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка, предсказание для n-го объекта: 1\n",
      "Проверка, критерий Gini: 0.4898\n",
      "Проверка, еще раз критерий Gini: 0.4898\n"
     ]
    }
   ],
   "source": [
    "print(f\"Проверка, предсказание для n-го объекта: {my_cls.classify_obj(train_data[4], my_cls.dtree):.0f}\")\n",
    "print(f\"Проверка, критерий Gini: {my_cls.dtree.gini(np.array([0]*6 + [1]*8)):.4f}\")\n",
    "print(f\"Проверка, еще раз критерий Gini: {Node.gini(np.array([0]*6 + [1]*8)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34681483",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_answers = my_cls.labels_predict(train_data)\n",
    "test_answers = my_cls.labels_predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c485f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_metric: 0.9857\n",
      "test_metric:  1.0000\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_metric: {my_cls.dtree.accuracy_metric(train_labels, train_answers):.4f}\")\n",
    "print(f\"test_metric:  {my_cls.dtree.accuracy_metric(test_labels, test_answers):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097b1e8c",
   "metadata": {},
   "source": [
    "### Вывод по второму заданию:\n",
    "<font size=4 color=\"green\">Метрики на основе критерия gini и энтропии Шеннона ведут себя практически идентично.</font>\n",
    "\n",
    "На данном игрушечном датасете разницы вообще не видно, метрики равны на столько, что я усомнился, что сделал все правильно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083a82a9",
   "metadata": {},
   "source": [
    "#### 3\\*. Реализуйте дерево для задачи регрессии.\n",
    "Возьмите за основу дерево, реализованное в методичке, заменив механизм предсказания в листе на взятие среднего значения по выборке, а критерий Джини на дисперсию значений. Проверьте точность предсказания дерева на одной из метрик задачи регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f3a7f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3 задание\n",
    "from sklearn import datasets\n",
    "\n",
    "regression_data, regression_labels = datasets.make_regression(n_samples=100, \n",
    "                                                              n_features=1, \n",
    "                                                              noise=10, \n",
    "                                                              random_state=42)\n",
    "\n",
    "plt.figure(figsize=(6,6), facecolor=\"g\")\n",
    "plt.scatter(regression_data, regression_labels, c='darkorange', edgecolor='black', s=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32eaaa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(regression_data, regression_labels, \n",
    "                                                    test_size=.3, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f76e45ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_DecisionTreeRegressor:\n",
    "    \n",
    "    def __init__(self, criterion=\"mse\", min_samples_leaf=1, max_leaf_nodes=None):\n",
    "        self.criterion = criterion\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        \n",
    "    def reg_fit(self, X, y, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        quality, t, index = Node_reg.reg_find_best_split(self, X, y)\n",
    "        if (t is None) or (index is None):\n",
    "            return Leaf_reg(X, y)\n",
    "        true_X, false_X, true_y, false_y = Node_reg.reg_split(X, y, index, t)\n",
    "        if (len(true_X) <= self.min_samples_leaf) or (len(false_X) <= self.min_samples_leaf):\n",
    "            return Leaf_reg(X, y)\n",
    "        if max_depth is not None:\n",
    "            if max_depth != 0:\n",
    "                max_d = max_depth - 1\n",
    "                true_branch = my_DecisionTreeRegressor.reg_fit(self, true_X, true_y, max_depth=max_d)\n",
    "                false_branch = my_DecisionTreeRegressor.reg_fit(self, false_X, false_y, max_depth=max_d)\n",
    "            else:\n",
    "                return Leaf_reg(X, y)\n",
    "        else:\n",
    "            true_branch = my_DecisionTreeRegressor.reg_fit(self, true_X, true_y)\n",
    "            false_branch = my_DecisionTreeRegressor.reg_fit(self, false_X, false_y)\n",
    "        self.reg_dtree = Node_reg(index, t, true_branch, false_branch)\n",
    "        # т.е. метод reg_fit() возвращает атрибут объекта regressor (экземпляр класса \n",
    "        # my_DecisionTreeRegressor) содержащий обученный экземпляр объекта дерева (класса Node); \n",
    "        # попросту говоря возвращает обученное дерево;\n",
    "        return self.reg_dtree\n",
    "    \n",
    "    @staticmethod\n",
    "    def predict_obj(obj, node):\n",
    "        if isinstance(node, Leaf_reg):\n",
    "            answer = node.pred_value\n",
    "            return answer\n",
    "        if obj[node.index] <= node.t:\n",
    "            return my_DecisionTreeRegressor.predict_obj(obj, node.true_branch)\n",
    "        else:\n",
    "            return my_DecisionTreeRegressor.predict_obj(obj, node.false_branch)\n",
    "    \n",
    "    def reg_predict(self, X):\n",
    "        pred_vec = []\n",
    "        for obj in X:\n",
    "            pred_val = my_DecisionTreeRegressor.predict_obj(obj, self.reg_dtree)\n",
    "            pred_vec.append(pred_val)\n",
    "        return pred_vec\n",
    "\n",
    "    \n",
    "######    \n",
    "class Leaf_reg:\n",
    "    def __init__(self, X, y):\n",
    "        self.feat_values = X\n",
    "        self.targ_values = y\n",
    "        self.pred_value = np.mean(self.targ_values)\n",
    "\n",
    "\n",
    "######    \n",
    "class Node_reg:\n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index\n",
    "        self.t = t\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "\n",
    "    @staticmethod\n",
    "    def reg_quality(targ_val_l, targ_val_r, disp_curr):\n",
    "        disp_left = np.var(targ_val_l)\n",
    "        disp_righ = np.var(targ_val_r)\n",
    "        weig = float(targ_val_l.shape[0]) / (targ_val_l.shape[0] + targ_val_r.shape[0])\n",
    "        return disp_curr - weig * disp_left - (1 - weig) * disp_righ\n",
    "    \n",
    "    @staticmethod\n",
    "    def reg_split(X, y, index, t):\n",
    "        left = np.where(X[:, index] <= t)\n",
    "        right = np.where(X[:, index] > t)\n",
    "        true_X = X[left]\n",
    "        false_X = X[right]\n",
    "        true_y = y[left]\n",
    "        false_y = y[right]\n",
    "        return true_X, false_X, true_y, false_y\n",
    "    \n",
    "    def reg_find_best_split(self, X, y):\n",
    "        disp_curr = np.var(y)\n",
    "        best_quality = 0\n",
    "        best_t = None\n",
    "        best_index = None\n",
    "        n_features = X.shape[1]\n",
    "        for index in range(n_features):\n",
    "            t_values = np.unique([row[index] for row in X])\n",
    "            for t in t_values:\n",
    "                true_X, false_X, true_y, false_y = Node_reg.reg_split(X, y, index, t)\n",
    "                if len(true_X) < self.min_samples_leaf or len(false_X) < self.min_samples_leaf:\n",
    "                    continue\n",
    "                current_quality = Node_reg.reg_quality(true_y, false_y, disp_curr)\n",
    "                if current_quality > best_quality:\n",
    "                    best_quality, best_t, best_index = current_quality, t, index\n",
    "        return best_quality, best_t, best_index\n",
    "\n",
    "    @staticmethod\n",
    "    def mse_metric(actual, predicted):\n",
    "        return np.mean((actual - predicted) ** 2)\n",
    "    \n",
    "\n",
    "######\n",
    "class ColorText:\n",
    "    PURPLE = '\\033[1;35;48m'\n",
    "    CYAN = '\\033[1;36;48m'\n",
    "    BOLD = '\\033[1;39;48m'\n",
    "    GREEN = '\\033[1;34;48m'\n",
    "    BLUE = '\\033[1;44;48m'\n",
    "    ORANGE = '\\033[1;32;48m'\n",
    "    YELLOW = '\\033[1;33;48m'\n",
    "    RED = '\\033[1;31;48m'\n",
    "    BLACK = '\\033[1;30;48m'\n",
    "    UNDERLINE = '\\033[1;37;48m'\n",
    "    END = '\\033[1;37;0m'\n",
    "\n",
    "def reg_print_tree(node, spacing=\"\"):\n",
    "    if isinstance(node, Leaf_reg):\n",
    "        print(ColorText.ORANGE + spacing + ' ЛИСТ' \n",
    "                  + ': прогноз = ' + str(node.pred_value) \n",
    "                  + ', объектов = ' + str(len(node.targ_values)) \n",
    "                  + ColorText.END)\n",
    "        return\n",
    "    print(ColorText.GREEN + spacing + 'УЗЕЛ'  \n",
    "              + ': индекс = ' + str(node.index) \n",
    "              + ', порог = ' + str(round(node.t, 2))\n",
    "              + ColorText.END)\n",
    "    print (spacing + '--> Левая ветка:')\n",
    "    reg_print_tree(node.true_branch, spacing + \"   \")\n",
    "    print (spacing + '--> Правая ветка:')\n",
    "    reg_print_tree(node.false_branch, spacing + \"   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c694424e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34;48mУЗЕЛ: индекс = 0, порог = -0.23\u001b[1;37;0m\n",
      "--> Левая ветка:\n",
      "\u001b[1;34;48m   УЗЕЛ: индекс = 0, порог = -1.41\u001b[1;37;0m\n",
      "   --> Левая ветка:\n",
      "\u001b[1;32;48m       ЛИСТ: прогноз = -75.59835646812401, объектов = 7\u001b[1;37;0m\n",
      "   --> Правая ветка:\n",
      "\u001b[1;34;48m      УЗЕЛ: индекс = 0, порог = -0.6\u001b[1;37;0m\n",
      "      --> Левая ветка:\n",
      "\u001b[1;32;48m          ЛИСТ: прогноз = -40.244173819607866, объектов = 9\u001b[1;37;0m\n",
      "      --> Правая ветка:\n",
      "\u001b[1;34;48m         УЗЕЛ: индекс = 0, порог = -0.46\u001b[1;37;0m\n",
      "         --> Левая ветка:\n",
      "\u001b[1;32;48m             ЛИСТ: прогноз = -23.03151004690616, объектов = 9\u001b[1;37;0m\n",
      "         --> Правая ветка:\n",
      "\u001b[1;32;48m             ЛИСТ: прогноз = -16.787450578114036, объектов = 6\u001b[1;37;0m\n",
      "--> Правая ветка:\n",
      "\u001b[1;34;48m   УЗЕЛ: индекс = 0, порог = 0.65\u001b[1;37;0m\n",
      "   --> Левая ветка:\n",
      "\u001b[1;34;48m      УЗЕЛ: индекс = 0, порог = 0.31\u001b[1;37;0m\n",
      "      --> Левая ветка:\n",
      "\u001b[1;34;48m         УЗЕЛ: индекс = 0, порог = -0.01\u001b[1;37;0m\n",
      "         --> Левая ветка:\n",
      "\u001b[1;32;48m             ЛИСТ: прогноз = -0.8281855692554628, объектов = 6\u001b[1;37;0m\n",
      "         --> Правая ветка:\n",
      "\u001b[1;32;48m             ЛИСТ: прогноз = 4.6111705563669405, объектов = 11\u001b[1;37;0m\n",
      "      --> Правая ветка:\n",
      "\u001b[1;32;48m          ЛИСТ: прогноз = 22.57747521692777, объектов = 7\u001b[1;37;0m\n",
      "   --> Правая ветка:\n",
      "\u001b[1;34;48m      УЗЕЛ: индекс = 0, порог = 1.06\u001b[1;37;0m\n",
      "      --> Левая ветка:\n",
      "\u001b[1;32;48m          ЛИСТ: прогноз = 43.55933646594026, объектов = 8\u001b[1;37;0m\n",
      "      --> Правая ветка:\n",
      "\u001b[1;32;48m          ЛИСТ: прогноз = 71.67037271048476, объектов = 7\u001b[1;37;0m\n"
     ]
    }
   ],
   "source": [
    "my_reg = my_DecisionTreeRegressor(min_samples_leaf=5)\n",
    "my_reg.reg_fit(train_X, train_y, max_depth=None)\n",
    "reg_print_tree(my_reg.reg_dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cad1a52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96864499])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51840eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_mse_metric: 84.2552\n",
      "test_mse_metric: 108.6150\n"
     ]
    }
   ],
   "source": [
    "my_reg.predict_obj(train_X[0], my_reg.reg_dtree)\n",
    "train_pred = my_reg.reg_predict(train_X)\n",
    "test_pred = my_reg.reg_predict(test_X)\n",
    "print(f\"train_mse_metric: {my_reg.reg_dtree.mse_metric(train_y, train_pred):.4f}\")\n",
    "print(f\"test_mse_metric: {Node_reg.mse_metric(test_y, test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cad491d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 77.74351303 104.10960417]\n",
      " [ 78.79791376 102.61196961]\n",
      " [ 83.46959329 111.93433245]\n",
      " [ 85.89613127 111.98016416]\n",
      " [ 84.25519406 108.61503032]\n",
      " [ 87.90124274 129.59079829]]\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "for param in range(1, 7):\n",
    "    my_reg = my_DecisionTreeRegressor(min_samples_leaf=param)\n",
    "    my_reg.reg_fit(train_X, train_y, max_depth=4)\n",
    "    train_pred = my_reg.reg_predict(train_X)\n",
    "    test_pred = my_reg.reg_predict(test_X)\n",
    "    metrics.append((my_reg.reg_dtree.mse_metric(train_y, train_pred), \n",
    "                    Node_reg.mse_metric(test_y, test_pred)))\n",
    "print(np.array(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27bfc278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1efce7af310>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regression_pred = my_reg.reg_predict(regression_data)\n",
    "plt.figure(figsize=(10,8), facecolor=\"g\")\n",
    "plt.scatter(regression_data, regression_labels, c=\"red\", edgecolor=\"black\", s=30)\n",
    "plt.scatter(regression_data, regression_pred, c=\"green\", edgecolor=\"black\", s=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8f2f30",
   "metadata": {},
   "source": [
    "#### В целом модель \"ухватила\" закономерность в данных. Интересно что получился такой ступенчатый ответ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcfdc53",
   "metadata": {},
   "source": [
    "PS/\n",
    "Пространства имен модели классификации и регрессии перекрываются.\n",
    "\n",
    "Если выполнить ячейку с моделью классификации, то потом выдают ошибку обращения к методом регрессионной модели и наоборот, если последней выполенна ячейка с кодом регрессионной модели, корректно работают обращения к методам регрессионной модели, а сбоят обращения к методам модели классификации.\n",
    "\n",
    "Я постарался переназвать методы в регрессионной модели добавлением префикса `reg_`\n",
    "\n",
    "<font color=\"green\">Теперь всё работает как надо!))))</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
